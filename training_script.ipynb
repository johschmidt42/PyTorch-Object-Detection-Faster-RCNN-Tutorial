{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import pathlib\n",
    "from dataclasses import dataclass, field\n",
    "from typing import List, Optional, Tuple\n",
    "\n",
    "import albumentations as albu\n",
    "import numpy as np\n",
    "from pytorch_lightning import Trainer, seed_everything\n",
    "from pytorch_lightning.callbacks import (\n",
    "    EarlyStopping,\n",
    "    LearningRateMonitor,\n",
    "    ModelCheckpoint,\n",
    ")\n",
    "from pytorch_lightning.loggers.neptune import NeptuneLogger\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from pytorch_faster_rcnn_tutorial.backbone_resnet import ResNetBackbones\n",
    "from pytorch_faster_rcnn_tutorial.datasets import ObjectDetectionDataSet\n",
    "from pytorch_faster_rcnn_tutorial.faster_RCNN import (\n",
    "    FasterRCNNLightning,\n",
    "    get_faster_rcnn_resnet,\n",
    ")\n",
    "from pytorch_faster_rcnn_tutorial.transformations import (\n",
    "    AlbumentationWrapper,\n",
    "    Clip,\n",
    "    ComposeDouble,\n",
    "    FunctionWrapperDouble,\n",
    "    normalize_01,\n",
    ")\n",
    "from pytorch_faster_rcnn_tutorial.utils import (\n",
    "    collate_double,\n",
    "    get_filenames_of_path,\n",
    "    log_mapping_neptune,\n",
    "    log_model_neptune,\n",
    "    log_packages_neptune,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper-parameters\n",
    "@dataclass\n",
    "class Params:\n",
    "    BATCH_SIZE: int = 2\n",
    "    OWNER: str = \"johschmidt42\"  # set your name here, e.g. johndoe22\n",
    "    SAVE_DIR: Optional[\n",
    "        str\n",
    "    ] = None  # checkpoints will be saved to cwd (current working directory)\n",
    "    LOG_MODEL: bool = False  # whether to log the model to neptune after training\n",
    "    GPU: Optional[int] = None  # set to None for cpu training\n",
    "    LR: float = 0.001\n",
    "    PRECISION: int = 32\n",
    "    CLASSES: int = 2\n",
    "    SEED: int = 42\n",
    "    PROJECT: str = \"Heads\"\n",
    "    EXPERIMENT: str = \"heads\"\n",
    "    MAXEPOCHS: int = 500\n",
    "    PATIENCE: int = 50\n",
    "    BACKBONE: ResNetBackbones = ResNetBackbones.RESNET34\n",
    "    FPN: bool = False\n",
    "    ANCHOR_SIZE: Tuple[Tuple[int, ...], ...] = ((32, 64, 128, 256, 512),)\n",
    "    ASPECT_RATIOS: Tuple[Tuple[float, ...]] = ((0.5, 1.0, 2.0),)\n",
    "    MIN_SIZE: int = 1024\n",
    "    MAX_SIZE: int = 1025\n",
    "    IMG_MEAN: List = field(default_factory=lambda: [0.485, 0.456, 0.406])\n",
    "    IMG_STD: List = field(default_factory=lambda: [0.229, 0.224, 0.225])\n",
    "    IOU_THRESHOLD: float = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# root directory\n",
    "ROOT_PATH = pathlib.Path.cwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = Params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# api key\n",
    "api_key = os.environ['NEPTUNE']  # if this throws an error, you didn't set your env var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save directory\n",
    "save_dir = os.getcwd() if not params.SAVE_DIR else params.SAVE_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# root directory\n",
    "root = ROOT_PATH / \"pytorch_faster_rcnn_tutorial\" / \"data\" / \"heads\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input and target files\n",
    "inputs = get_filenames_of_path(root / 'input')\n",
    "targets = get_filenames_of_path(root / 'target')\n",
    "\n",
    "inputs.sort()\n",
    "targets.sort()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping\n",
    "mapping = {\n",
    "    'head': 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training transformations and augmentations\n",
    "transforms_training = ComposeDouble(\n",
    "    [\n",
    "        Clip(),\n",
    "        AlbumentationWrapper(albumentation=albu.HorizontalFlip(p=0.5)),\n",
    "        AlbumentationWrapper(\n",
    "            albumentation=albu.RandomScale(p=0.5, scale_limit=0.5)\n",
    "        ),\n",
    "        # AlbuWrapper(albu=A.VerticalFlip(p=0.5)),\n",
    "        FunctionWrapperDouble(np.moveaxis, source=-1, destination=0),\n",
    "        FunctionWrapperDouble(normalize_01),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation transformations\n",
    "transforms_validation = ComposeDouble([\n",
    "    Clip(),\n",
    "    FunctionWrapperDouble(np.moveaxis, source=-1, destination=0),\n",
    "    FunctionWrapperDouble(normalize_01)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test transformations\n",
    "transforms_test = ComposeDouble([\n",
    "    Clip(),\n",
    "    FunctionWrapperDouble(np.moveaxis, source=-1, destination=0),\n",
    "    FunctionWrapperDouble(normalize_01)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random seed\n",
    "seed_everything(params.SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training validation test split\n",
    "inputs_train, inputs_valid, inputs_test = inputs[:12], inputs[12:16], inputs[16:]\n",
    "targets_train, targets_valid, targets_test = targets[:12], targets[12:16], targets[16:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset training\n",
    "dataset_train = ObjectDetectionDataSet(inputs=inputs_train,\n",
    "                                       targets=targets_train,\n",
    "                                       transform=transforms_training,\n",
    "                                       use_cache=True,\n",
    "                                       convert_to_format=None,\n",
    "                                       mapping=mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset validation\n",
    "dataset_valid = ObjectDetectionDataSet(inputs=inputs_valid,\n",
    "                                       targets=targets_valid,\n",
    "                                       transform=transforms_validation,\n",
    "                                       use_cache=True,\n",
    "                                       convert_to_format=None,\n",
    "                                       mapping=mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset test\n",
    "dataset_test = ObjectDetectionDataSet(inputs=inputs_test,\n",
    "                                      targets=targets_test,\n",
    "                                      transform=transforms_test,\n",
    "                                      use_cache=True,\n",
    "                                      convert_to_format=None,\n",
    "                                      mapping=mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader training\n",
    "dataloader_train = DataLoader(\n",
    "    dataset=dataset_train,\n",
    "    batch_size=params.BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    collate_fn=collate_double,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader validation\n",
    "dataloader_valid = DataLoader(dataset=dataset_valid,\n",
    "                              batch_size=1,\n",
    "                              shuffle=False,\n",
    "                              num_workers=0,\n",
    "                              collate_fn=collate_double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader test\n",
    "dataloader_test = DataLoader(dataset=dataset_test,\n",
    "                             batch_size=1,\n",
    "                             shuffle=False,\n",
    "                             num_workers=0,\n",
    "                             collate_fn=collate_double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neptune logger\n",
    "neptune_logger = NeptuneLogger(\n",
    "    api_key=api_key,\n",
    "    project_name=f\"{params.OWNER}/{params.PROJECT}\",  # use your neptune name here\n",
    "    experiment_name=params.PROJECT,\n",
    "    params=params.__dict__,\n",
    ")\n",
    "\n",
    "assert neptune_logger.name  # http GET request to check if the project exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model init\n",
    "model = get_faster_rcnn_resnet(\n",
    "    num_classes=params.CLASSES,\n",
    "    backbone_name=params.BACKBONE,\n",
    "    anchor_size=params.ANCHOR_SIZE,\n",
    "    aspect_ratios=params.ASPECT_RATIOS,\n",
    "    fpn=params.FPN,\n",
    "    min_size=params.MIN_SIZE,\n",
    "    max_size=params.MAX_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lightning init\n",
    "task = FasterRCNNLightning(\n",
    "    model=model, lr=params.LR, iou_threshold=params.IOU_THRESHOLD\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks\n",
    "checkpoint_callback = ModelCheckpoint(monitor=\"Validation_mAP\", mode=\"max\")\n",
    "learningrate_callback = LearningRateMonitor(\n",
    "    logging_interval=\"step\", log_momentum=False\n",
    ")\n",
    "early_stopping_callback = EarlyStopping(\n",
    "    monitor=\"Validation_mAP\", patience=params.PATIENCE, mode=\"max\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer init\n",
    "trainer = Trainer(\n",
    "    gpus=params.GPU,\n",
    "    precision=params.PRECISION,  # try 16 with enable_pl_optimizer=False\n",
    "    callbacks=[checkpoint_callback, learningrate_callback, early_stopping_callback],\n",
    "    default_root_dir=save_dir,  # where checkpoints are saved to\n",
    "    logger=neptune_logger,\n",
    "    log_every_n_steps=1,\n",
    "    num_sanity_val_steps=0,\n",
    "    max_epochs=params.MAXEPOCHS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start training\n",
    "trainer.fit(\n",
    "    model=task, train_dataloader=dataloader_train, val_dataloaders=dataloader_valid\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start testing\n",
    "trainer.test(ckpt_path=\"best\", dataloaders=dataloader_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log mapping as table\n",
    "log_mapping_neptune(mapping=mapping, neptune_logger=neptune_logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log mapping as table\n",
    "log_mapping_neptune(mapping, neptune_logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log model\n",
    "if params.LOG_MODEL:\n",
    "    checkpoint_path = pathlib.Path(checkpoint_callback.best_model_path)\n",
    "    log_model_neptune(\n",
    "        checkpoint_path=checkpoint_path,\n",
    "        save_directory=pathlib.Path.home(),\n",
    "        name=\"best_model.pt\",\n",
    "        neptune_logger=neptune_logger,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop logger\n",
    "neptune_logger.experiment.stop()\n",
    "print(\"Finished\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
